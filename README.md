# AdminBert_Project

This anonymous repo contains data and part of the models finetuned and Pretrained during our experiments. 

- In the section data, you will find a sample extraction of the data used for the continual pretraining of our models AdminBERT; the training file contains 30,000 text fragments, and the test file contains 6000 text fragments.
- 

